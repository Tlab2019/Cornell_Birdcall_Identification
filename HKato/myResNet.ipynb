{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Birdsong Pytorch Baseline: ResNeSt50-fast (Inference) を参考にした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-251567ac936a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import yaml\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import cv2\n",
    "import librosa\n",
    "import audioread\n",
    "import soundfile as sf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv2d, Module, Linear, BatchNorm2d, ReLU\n",
    "from torch.nn.modules.utils import _pair\n",
    "import torch.utils.data as data\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21375 entries, 0 to 21374\n",
      "Data columns (total 35 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   rating            21375 non-null  float64\n",
      " 1   playback_used     19575 non-null  object \n",
      " 2   ebird_code        21375 non-null  object \n",
      " 3   channels          21375 non-null  object \n",
      " 4   date              21375 non-null  object \n",
      " 5   pitch             21375 non-null  object \n",
      " 6   duration          21375 non-null  int64  \n",
      " 7   filename          21375 non-null  object \n",
      " 8   speed             21375 non-null  object \n",
      " 9   species           21375 non-null  object \n",
      " 10  number_of_notes   21375 non-null  object \n",
      " 11  title             21375 non-null  object \n",
      " 12  secondary_labels  21375 non-null  object \n",
      " 13  bird_seen         19575 non-null  object \n",
      " 14  sci_name          21375 non-null  object \n",
      " 15  location          21375 non-null  object \n",
      " 16  latitude          21375 non-null  object \n",
      " 17  sampling_rate     21375 non-null  object \n",
      " 18  type              21375 non-null  object \n",
      " 19  elevation         21375 non-null  object \n",
      " 20  description       15176 non-null  object \n",
      " 21  bitrate_of_mp3    21367 non-null  object \n",
      " 22  file_type         21375 non-null  object \n",
      " 23  volume            21375 non-null  object \n",
      " 24  background        8300 non-null   object \n",
      " 25  xc_id             21375 non-null  int64  \n",
      " 26  url               21375 non-null  object \n",
      " 27  country           21375 non-null  object \n",
      " 28  author            21375 non-null  object \n",
      " 29  primary_label     21375 non-null  object \n",
      " 30  longitude         21375 non-null  object \n",
      " 31  length            21375 non-null  object \n",
      " 32  time              21375 non-null  object \n",
      " 33  recordist         21375 non-null  object \n",
      " 34  license           21375 non-null  object \n",
      "dtypes: float64(1), int64(2), object(32)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./rawdata/train.csv\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "species=train.species.value_counts()\n",
    "birds=train.ebird_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_split_stfit_datasets(birds, species, interval=5):\n",
    "#     audio_dir_path=\"./rawdata/train_audio/\"\n",
    "#     for bird_name in tqdm(birds):\n",
    "#         print(\"---------------- {} ----------------\".format(bird_name))\n",
    "#         if not os.path.exists(os.path.join('data', bird_name)):\n",
    "#             os.mkdir(os.path.join('data', bird_name))\n",
    "#         files = train[train.ebird_code==bird_name]['filename'].values\n",
    "#         for file in tqdm(files, leave=False):\n",
    "#             try:\n",
    "#                 audio_path=os.path.join(audio_dir_path,bird_name,file)\n",
    "#                 x , sr = librosa.load(audio_path)\n",
    "#                 print(\"Audio Length: {}\".format(len(x) / sr))\n",
    "#                 i = 0\n",
    "#                 while ((i+interval) * sr < len(x)):\n",
    "#                     sub_x = x[i*sr:(i+interval)*sr]\n",
    "#                     sub_x = librosa.stft(sub_x)\n",
    "#                     Xdb = librosa.amplitude_to_db(abs(sub_x))\n",
    "#                     np.savetxt('./data/{}/{}_{}_{}to{}sec.csv'.format(bird_name, bird_name, file.split('.')[0], i, i+interval), Xdb)\n",
    "#                     i = i + interval\n",
    "#             except:\n",
    "#                 print(\"some errors occered!\")\n",
    "# interval = 5\n",
    "# create_split_stfit_datasets(birds, species, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像のサイズ指定\n",
    "ScaleTo = 256\n",
    "seed = 7\n",
    "n_categories = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#トレーニングデータの読み込み\n",
    "data_dir =\"../input/train\"\n",
    "path = \"../input/train/*/*.png\"\n",
    "files = glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImg = []\n",
    "trainLabel = []\n",
    "j = 1\n",
    "num = len(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像データをリストに格納\n",
    "for img in files:\n",
    "    print(str(j) + \"/\" + str(num) , end=\"\\r\")\n",
    "    trainImg.append(cv2.resize(cv2.imread(img) ,(ScaleTo,ScaleTo)))\n",
    "    #trainLabel.append(img.split(\"/\")[-2])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ラベルをリストに格納\n",
    "for dir in os.listdir(data_dir):\n",
    "    if dir == \".DS_Store\":\n",
    "        continue\n",
    "    dir1 = data_dir + \"/\" + dir\n",
    "    label = dir\n",
    "\n",
    "    for file in os.listdir(dir1):\n",
    "        if file != \"Thumbs.db\":\n",
    "\n",
    "            trainLabel.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kerasに渡すためにnumpy配列に変換。\n",
    "image_list = np.asarray(trainImg)\n",
    "label_list = pd.DataFrame(trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearTrainImg = []\n",
    "examples = [];getEx = True\n",
    "\n",
    "for img in image_list:\n",
    "    #ぼかしを入れてノイズを除去\n",
    "    blurImg = cv2.GaussianBlur(img ,(5,5),0)\n",
    "    #RGBからHSVに変換\n",
    "    hsvImg = cv2.cvtColor(blurImg , cv2.COLOR_BGR2HSV)\n",
    "    #マスクを作成\n",
    "    lower_green = (25,40,50)\n",
    "    upper_green = (75,255,255)\n",
    "    mask = cv2.inRange(hsvImg , lower_green ,upper_green)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n",
    "    mask = cv2.morphologyEx(mask , cv2.MORPH_CLOSE,kernel)\n",
    "\n",
    "    #ブールマスクの作成\n",
    "    bMask = mask > 0\n",
    "\n",
    "    #マスクの適用\n",
    "    #空のイメージの作成\n",
    "    clear = np.zeros_like(img , np.uint8)\n",
    "    #オリジナル画像にブールマスクを適用\n",
    "    clear[bMask] = img[bMask]\n",
    "\n",
    "    clearTrainImg.append(clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(clearTrainImg[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearTrainImg = np.asarray(clearTrainImg)\n",
    "clearTrainImg.shape\n",
    "# クラスの形式を変換\n",
    "le = LabelEncoder()\n",
    "le = le.fit(label_list)\n",
    "label_list = le.transform(label_list)\n",
    "label_list\n",
    "label_list = np_utils.to_categorical(label_list)\n",
    "label_list\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clearTrainImg, label_list, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=180,  # randomly rotate images in the range\n",
    "        zoom_range = 0.1, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1,  # randomly shift images vertically\n",
    "        horizontal_flip=True,  # randomly flip images horizontally\n",
    "        vertical_flip=True  # randomly flip images vertically\n",
    "    )\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル作成・学習\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D,Input\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation,GlobalAveragePooling2D,Input\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "# ResNet50のロード。FC層は不要なので include_top=False\n",
    "input_tensor = Input(shape=(ScaleTo, ScaleTo, 3))\n",
    "resnet50 = ResNet50(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# FC層の作成\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=resnet50.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# ResNet50とFC層を結合してモデルを作成\n",
    "resnet50_model = Model(input=resnet50.input, output=top_model(resnet50.output))\n",
    "\n",
    "#ResNet50の一部の重みを固定\n",
    "for layer in resnet50_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 多クラス分類を指定\n",
    "resnet50_model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
    "          metrics=['accuracy'])\n",
    "resnet50_model.summary()\n",
    "\n",
    "\n",
    "#学習の実行\n",
    "hist = resnet50_model.fit_generator(datagen.flow(X_train, y_train, batch_size=75),\n",
    "                        epochs=35, validation_data=(X_test, y_test),\n",
    "                        steps_per_epoch=X_train.shape[0])\n",
    "\n",
    "\n",
    "                        steps_per_epoch=X_train.shape[0])\n",
    "\n",
    "\n",
    "#モデルの評価\n",
    "print(resnet50_model.evaluate(X_train, y_train)) #トレーニングの精度\n",
    "print(resnet50_model.evaluate(X_test, y_test))  #テスト精度\n",
    "\n",
    "\n",
    "#パラメータの保存\n",
    "model.save_weights('../content/weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
