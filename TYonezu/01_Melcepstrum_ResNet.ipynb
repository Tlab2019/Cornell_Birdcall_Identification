{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import plotly.express as px\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import warnings\n",
    "import glob\n",
    "import IPython\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "#必要なライブラリの読み込み\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_place = \"local_machine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: D:\\kaggle_data\\birdsong-recognition\\mydata\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# データセットのパスを設定する\n",
    "##############################\n",
    "\n",
    "#ローカル用\n",
    "if exec_place == \"local_machine\":\n",
    "    import win32com.client\n",
    "    dir = \"mydata.lnk\"\n",
    "    wshell = win32com.client.Dispatch(\"WScript.Shell\") # <COMObject WScript.Shell>\n",
    "    dir = wshell.CreateShortcut(dir).TargetPath\n",
    "    \n",
    "#Kaggle Notebook用\n",
    "if exec_place == \"kaggle_kernel\":\n",
    "    dir = \"../input/birdsong-recognition/\"\n",
    "    \n",
    "if not(os.path.exists(os.path.join(dir))):\n",
    "    os.makedirs(dir)\n",
    "    \n",
    "print(\"dir:\",dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/21374\r"
     ]
    }
   ],
   "source": [
    "#画像のサイズ指定\n",
    "ScaleTo = 100\n",
    "seed = 7\n",
    "n_categories = 12\n",
    "\n",
    "#トレーニングデータの読み込み\n",
    "data_dir = os.path.join(dir,\"train_melcepstrum\")\n",
    "path = os.path.join(data_dir,\"*\",\"*.pkl\")\n",
    "files = glob(path)\n",
    "\n",
    "trainImg = []\n",
    "trainLabel = []\n",
    "j = 1\n",
    "num = len(files)\n",
    "\n",
    "#画像データをリストに格納\n",
    "for f in files[:300]:\n",
    "    print(str(j) + \"/\" + str(num) , end=\"\\r\")\n",
    "    \n",
    "    img = pd.read_pickle(f)\n",
    "    img = img.values\n",
    "    img = cv2.resize(img,(ScaleTo,ScaleTo))\n",
    "    img = img[:,:,np.newaxis]\n",
    "    \n",
    "    #print(img)\n",
    "    trainImg.append(img)\n",
    "    trainLabel.append(f.split(os.path.sep)[-2])\n",
    "    \n",
    "    if j <= 0:\n",
    "        plt.imshow(img[:,:,0])\n",
    "        plt.show()\n",
    "    \n",
    "    j += 1\n",
    "\n",
    "\n",
    "#ラベルをリストに格納\n",
    "for dir in os.listdir(data_dir):\n",
    "    if dir == \".DS_Store\":\n",
    "        continue\n",
    "    dir1 = data_dir + \"/\" + dir\n",
    "    label = dir\n",
    "\n",
    "    for file in os.listdir(dir1):\n",
    "        if file != \"Thumbs.db\":\n",
    "\n",
    "            trainLabel.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [300, 21674]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-5e46376baee5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclearTrainImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2094\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2096\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [300, 21674]"
     ]
    }
   ],
   "source": [
    "# kerasに渡すためにnumpy配列に変換。\n",
    "image_list = np.asarray(trainImg)\n",
    "label_list = pd.DataFrame(trainLabel)\n",
    "\n",
    "\n",
    "clearTrainImg = []\n",
    "examples = [];getEx = True\n",
    "\n",
    "for img in image_list:\n",
    "    #ぼかしを入れてノイズを除去\n",
    "    blurImg = cv2.GaussianBlur(img ,(5,5),0)\n",
    "    #RGBからHSVに変換\n",
    "    hsvImg = cv2.cvtColor(blurImg , cv2.COLOR_BGR2HSV)\n",
    "    #マスクを作成\n",
    "    lower_green = (25,40,50)\n",
    "    upper_green = (75,255,255)\n",
    "    mask = cv2.inRange(hsvImg , lower_green ,upper_green)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n",
    "    mask = cv2.morphologyEx(mask , cv2.MORPH_CLOSE,kernel)\n",
    "\n",
    "    #ブールマスクの作成\n",
    "    bMask = mask > 0\n",
    "\n",
    "    #マスクの適用\n",
    "    #空のイメージの作成\n",
    "    clear = np.zeros_like(img , np.uint8)\n",
    "    #オリジナル画像にブールマスクを適用\n",
    "    clear[bMask] = img[bMask]\n",
    "\n",
    "    clearTrainImg.append(clear)\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(clearTrainImg[i])\n",
    "\n",
    "\n",
    "clearTrainImg = np.asarray(clearTrainImg)\n",
    "clearTrainImg.shape\n",
    "# クラスの形式を変換\n",
    "le = LabelEncoder()\n",
    "le = le.fit(label_list)\n",
    "label_list = le.transform(label_list)\n",
    "label_list\n",
    "label_list = np_utils.to_categorical(label_list)\n",
    "label_list\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clearTrainImg, label_list, test_size=0.33, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=180,  # randomly rotate images in the range\n",
    "        zoom_range = 0.1, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1,  # randomly shift images vertically\n",
    "        horizontal_flip=True,  # randomly flip images horizontally\n",
    "        vertical_flip=True  # randomly flip images vertically\n",
    "    )\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#モデル作成・学習\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D,Input\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation,GlobalAveragePooling2D,Input\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "# ResNet50のロード。FC層は不要なので include_top=False\n",
    "input_tensor = Input(shape=(ScaleTo, ScaleTo, 3))\n",
    "resnet50 = ResNet50(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# FC層の作成\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=resnet50.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# ResNet50とFC層を結合してモデルを作成\n",
    "resnet50_model = Model(input=resnet50.input, output=top_model(resnet50.output))\n",
    "\n",
    "#ResNet50の一部の重みを固定\n",
    "for layer in resnet50_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 多クラス分類を指定\n",
    "resnet50_model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
    "          metrics=['accuracy'])\n",
    "resnet50_model.summary()\n",
    "\n",
    "\n",
    "#学習の実行\n",
    "hist = resnet50_model.fit_generator(datagen.flow(X_train, y_train, batch_size=75),\n",
    "                        epochs=35, validation_data=(X_test, y_test),\n",
    "                        steps_per_epoch=X_train.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "#モデルの評価\n",
    "print(resnet50_model.evaluate(X_train, y_train)) #トレーニングの精度\n",
    "print(resnet50_model.evaluate(X_test, y_test))  #テスト精度\n",
    "\n",
    "\n",
    "#パラメータの保存\n",
    "model.save_weights('../content/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
